\section{Encrypting content}

\section{Keys generation}
\subsection{Randomly derived}
  manual backup of the keys
\subsection{Keys derived from a password}

\section{Resilience against malicious nodes}

 \subsection{Reputation systems}
Reputation systems mitigate the problem of malicious nodes in
P2P networks, trying to build trust among the nodes. The key
idea of a reputation system is to predict the future behaviour
of nodes based on feedback about their past transactions [1]. A
transaction is application dependent, for example forwarding a
message in the network, buying an item in e-commerce services,
share or store files, etc. After a transaction, the client node emits
a recommendation that evaluates the behaviour of the other peer.
The aggregation of these recommendations leads to a reputation
value.
A reputation system built on top of a DHT has the ability
to compute a global reputation value for every node. Indeed
all the recommendations about a single node can be handled
consistently at a common location: either by a specific node
or by a set of nodes. Among existing reputation systems for
DHTs, we can cite: PeerTrust~\cite{peertrust}, WTR~\cite{wtr},
Eigentrust~\cite{eigentrust},
PowerTrust~\cite{powertrust} and CORPS~\cite{corps}

Reputation systems have to deal with malicious nodes that:
do not participate, collude with other malicious nodes and
emit false recommendations. There are techniques to mitigate
the impact of these attacks, such as the ones presented in
TrustGuard~\cite{trustguard} and WTR~\cite{wtr}. Nevertheless, to our knowledge,
none of the existing solutions to promote trust in P2P can be
$100\%$ effective in detecting and blocking these attacks.

It's assumed an $5\%$ error in the clasification of trusted nodes.


\paragraph{CORPS trust model}
They consider a probabilistic model of trust based on reputation.
The reputation value $R(X)$ is the probability that node $X$ will
be honest in the future. This reputation value is computed
according to a list of recommendations emitted by nodes that
have already carried out transactions with $X$.
After each transaction, a node emits a recommendation
about its peer. A node may lie: it may emit negative
recommendations about a peer that behaves correctly, or
positive recommendations about a malicious peer. Several nodes
may collude to increase or decrease the reputation value of
another node. These problems generate a deviation between
the computed reputation of the node and its real behaviour. It is
considered that this deviation depends on the function used to
compute the reputation value and on the percentage of malicious
nodes within the system.

It assumes a reputation system in the overlay structure with the following properties:
\begin{enumerate}
  \item Every node $X$ has an associated reputation value $R(X)$
  which represents the probability that $X$ is an honest node.
  \item $R(X)$ is computed using the recommendations emitted
  by nodes that have completed a transaction with $X$. Bad
  recommendations have a stronger effect on $R(X)$ than
  good ones. It should be more difficult for node to
  increase its reputation value than to decrease it.
  \item For every node $X$, $R(X)$ is highly available in the DHT.
\end{enumerate}

To avoid nodes that lie about a reputation value, it considers a reputation
system that computes the reputation of nodes concurrently on different nodes.
They decide individually if that node is reputable or not, using a voting
scheme in case of disagreement. On the whole, assuming that there is a smaller
percentage of malicious nodes in the network, the result avoids
false statements about reputation.

To maintain the same nomenclature used in CORPS, in all the following sections,
we call a node $n_i \in TS$ a trusted node, even if there still remains a
probability that this node's actual reputation is smaller than the threshold
$\rho$.
 
 
3.3 Self-Certification
A trusted authority issues identity certificates in a
centralized system. P. Dewan proposed a self-certification
mechanism [12] that splits the trusted entity among the
peers and enables them to generate their own identities in a
decentralized reputation system. Certified Authority (CA)
is run by each peer so as to issue an identity certificate(s)
for itself. These self certified certificates are similar to
SDSI certificates [9]. Each peer has its own reputation and
the reputations of all peers collectively form the reputation
of a CA.
In Self-certification mechanism there is no need for
centralized trusted entity which issues identities in a
centralized system. There is no way to map the identity of
a peer in the system to its real-life identity when they use
self-certified identities. They remain pseudonymous in the
system. The idea of making peers anonymous or
pseudonymous is desirable in P2P networks, but it can also
backfire sometimes.
In Self-certification mechanism the anonymity of the peers
is preserved by grouping of peers. The combination of self
certification and anonymity limits the possibility of a Sybil
attack. In contrast to the traditional CA-based approach,
neither the group authority nor the transacting peers can
establish the identity of the peer. In addition, certificate
revocations are not needed in the group-based approach as
the group authority only vouches for the real-life existence
of the peer, unlike the traditional certificate-based
approaches where various certificate attributes are attested
by the authority and necessitate revocation if any of those
attributes mutate in time. If a highly reputed identity is
compromised, its misuse would be self-destructive as its
reputation will go down if misused.

\chapter{System Overview}

In this section we describe the user idetification system. 
This system provides a distributed and secure way to attain a user-password
identification scheme like the ones commonly seen in centralized services.

\section{Architectural principles}
%The general view of the system consists in a multi-layered network based in trusted rings.
The general view of the system consists in a double-layered network; a Trusted
ring of nodes nested inside a normal DHT, with multiple routing policies
depending in the protocol of differents services. The user registration,
sign-in, logout and password change operations respectively allow a node to
register an user identity, to identify himself with an existing user identity,
to remove your user session and to change the password used to sign-in.

The system needs to have a \textit{trusted ring} maintained by periodical
checks of capacity of his members to remain in the trusted ring and a
reputation system to evaluate this. Also, similar to the
leafset concept in Pastry, each trusted node needs to maintain a
\textit{trustset}, wich basically consist in D numerically closest trusted
nodes with D/2 clockwise nodes, and D/2 counter-clockwise ones.

The system used to build the trusted node infraestructure in the P2P networks
needs to regularly asses the ability of the nodes to be part of the trusted
ring.

The figure shows a basic structure of the system. There are normal nodes and
trusted nodes. Every trusted nodes maintains a \textit{trustsets}.

A simple storage system is needed.
The \textit{trustsets} are in charge of the storage of the user keys that are
used to identify an user in the system. The system needs a PUT(key,
file) operation that stores the file in the closest trusted node based in the
routing algorithm and a GET(key) operation that retrieves the stored file.


We now describe our protocols based on the system model. 
%Figure 2 shows the information objects and
%their storage locations, with arrows for the abstract flow of the
%login procedure, Table I lists the terms used in the algorithms.
%A. Account Registration

\section{Account registration}

To register a new user account, the user first
has to choose a \textit{username} and a \textit{password}.
%The \textit{username} should be unique in the network.
% The user checks if the username exists by sending a
% REGISTER(username, identity_file: [[c(user_keys_file), salt]).
% This operation use a accounted routing algorithm that uses only trusted
% nodes. When the register operation reaches the closest node to the username,
% it propagates a TRUSTSET_USERNAME_REGISTRATION operation. This operation sends a
% call to each node in the trustset of the node, wich then pass to do a council
% meeting. If the meeting results in favor, each of them sends a
% OK_USERNAME_REGISTRATION(user_identity_file_name) to node doing the REGISTER operation.
% 
% DETAILS OF THE REGISTER OPERATION
% DETAILS OF THE COUNCIL MEETING --> Explain before, in trusted node part 
% 

% key store file
Considering a key-based authentication, the user creates a \textit{key store file}, containing all the
keys used by the P2P application the user wants to log in to.
The user generates a cryptographic key to authenticate the write operations
that will be made in the file, and store this key along with the others in the
\textit{key store file}.


% encryption and store of the key store file
The user then creates a \textit{symmetric key KKS} ,
encrypts the file content with this key and puts the ciphertext
into the storage, obtaining a \textit{file name fKS} . Now, the user
creates a \textit{login information file} by creating a random
byte string \textit{salt}, deriving a \textit{symmetric key KLI} from the user
\textit{password} and the \textit{salt}.
Using the new \textit{ symmetric key KLI}, the user encrypts the \textit{file name fKS},
the \textit{symmetric key KKS} and the \textit{cryptographic key to
authenticate the write operations KW}.
 The salt and the three encrypted values are put
into the storage, obtaining a file name fLI . The salt is stored
in plaintext, so that the user later can derive the decryption
key KLI by only providing the password. Finally, the user
performs the write-once operation put on the DHT with
uname as key and fLI as value.

%unique username
If the username was taken,
the user is prompted for a new username.

%finish
Once all operations
have succeeded, the user is registered in the system.


\section{Sign-in}
\section{Logout}
\section{Password Change}

\chapter{Evaluation}

In this section we present a theoretical evaluation of
the authentication system.
%, as well as a set of simulations and performance
%results.

%%%Theoretical evaluation

We suppose in the following that the underlying
reputation system makes an error $\varepsilon$ when classifying a
node $X$ with a reputation $R(x) \geq \rho$, where $\rho \in [ 0 \cdots 1 ]$,
and $ \varepsilon = f ( \rho )$. In other words, classifying a node $X$ as
honest because its reputation is greater than $\rho$ has a
probability of error $\varepsilon$.
Let $n$ be the size of the Trusted Ring. The probability
to have $k$ misclassified nodes in the Trusted Ring, that
is $k$ malicious nodes is:

$$
P_{k_{malicious}} = \left(\!
                          \begin{array}{c}
                            n\\
                            k
                          \end{array}
                    \!\right)              
                    \varepsilon^{n-k} ( 1 - \varepsilon )^k
$$

Then, the probability to have at most $k$ malicious
nodes in a Trusted Ring of size $n$ is:

$$
P_{\leq k} = \sum^{k}_{i=1} \left(\!
                                \begin{array}{c}
                                    n\\
                                    k
                                  \end{array}
                            \!\right)              
                    \varepsilon^{n-i} ( 1 - \varepsilon )^i
$$

Therefore, the probability to have $k$ or more malicious
nodes in a Trusted Ring of size $n$ is:

$$
P_{\leq k} = \sum^{n}_{i=k} \left(\!
                                \begin{array}{c}
                                    n\\
                                    i
                                  \end{array}
                            \!\right)              
                    \varepsilon^{n-i} ( 1 - \varepsilon )^i
$$

The user identification fails when:
\begin{enumerate}
  \item The user cannot retrieve his own PKI from the \textit{trustset}.
  \item or when the public key of the user fails to be retrieved.
\end{enumerate}

These failures can happen when the \textit{trustsets} storing the PKI or the public
key have more malicious nodes than normal nodes.

The probability that a \textit{trustset} has half or more malicious nodes, assuming a maximum
classification error for the underlying reputation system
of $5\%$, is .% FILL HERE
%Hence the probability for having a fully erroneous trustset is theoretically possible, but
%practically infeasible.

Considering a maximum error rate of $5\%$ is a typical
value for a reputation system. In some cases it may be
over-estimated (for more details, please refer the results
obtained for the WTR reputation system\cite{wrt_reputation_system}). This
error hardly depends on the total number of malicious
nodes in the network, and decreases when the ratio
of malicious node decreases. The less malicious nodes
there are in the system, the easier it is to discriminate
against them.



\section{Forgotten passwords}

\section{Password-recovery mechanisms}
  - Security questions
  - threshold-based secret sharing with delegate selection and encrypting
  shares with passwords

\section{Password Change}

